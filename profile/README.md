<div align="center">
  <h1>SmartSight: You Learn. We see. We remember.</h1>
  <p>üëì <b>Hands-free AI Study Coaching Service using Meta Ray-Ban Smart Glasses</b> üëì</p>
</div>

<br/>

<div align="center">
  <img src="./assets/team_photo1.jpg" alt="Team Photo 1" style="border-radius: 10px; width: 30%;"/>
  <img src="./assets/team_photo2.jpg" alt="Team Photo 2" style="border-radius: 10px; width: 30%;"/>
  <img src="./assets/team_photo3.jpg" alt="Team Photo 3" style="border-radius: 10px; width: 30%;"/>
</div>

<br/>

<div align="center">
  <a href="https://www.youtube.com/watch?v=YOUR_VIDEO_ID">üì∫ Demo Video (YouTube)</a> 
  &nbsp; | &nbsp;
  <a href="#">üì± iOS App Store (Coming Soon)</a>
</div>

---

## Achievements

- **MIT Reality Hack 2026 - Grand Prize (Gold Award) Winner**
- **MIT Reality Hack 2026 - Meta Track Winner**
- **Scheduled to attend AWE USA 2026** (World's #1 XR + AI Event)

---

## Project Overview

- **Project Name:** SmartSight (Luna)
- **Goal:** To eliminate the hassle of manual study logging and develop an AI coach that automatically analyzes and guides study sessions using the 1st-person perspective (POV) of Meta Ray-Ban glasses.
- **Core Value:** "Visualizing the learning journey without ever interrupting learning itself."

---

## Inspiration & Problem Statement

### **Limitations of Traditional Study Tracking**
* **Manual Logging Hassle:** Requirements for manual logging (starting timers, selecting subjects) break the flow and cause distractions.
* **Lacks Contextual Data:** Simply measuring 'study time' lacks the contextual feedback needed to understand what was actually covered.
* **Low Output vs. Input:** A lack of feedback loops means the energy spent on logging doesn't effectively lead to improved learning efficiency.

### **SmartSight‚Äôs Solution**
* **Hands-free Tracking:** Meta Ray-Ban cameras and microphones quietly observe and automatically log study sessions as they happen.
* **Contextual Insight:** AI analyzes 1st-person POV images to identify study content, engagement levels, and distractions (like phone usage).

---

## Key Features

### **1. Hands-Free Automatic Logging**
* Automatically tracks study sessions, subjects, and time spent without needing to touch a phone.
* AI automatically tags subjects (Biology, Math, etc.) and subtopics from the 1st-person POV images.

### **2. AI-Powered Contextual Analysis**
* **Learning State Analysis:** Determines if the student is actively solving problems or passively reading.
* **Study Telemetry:** Provides consistent, machine-readable metrics on learning quality using structured JSON data.
* **Distraction Monitoring:** Detects distractions, such as central phone visibility, within the user's field of view.

### **3. Real-time AI Coach**
* **Voice Support:** If you're "Stuck? Just ask" ‚Äî receive instant voice-based guidance without breaking focus.
* **Coaching Principles:** Specifically designed to avoid giving direct answers, instead asking reflective questions to encourage reasoning.

### **4. Learning Dashboard**
* Visualizes metrics such as time per topic, active/passive ratios, and help counts via an iOS application.

---

## Tech Stack

| Category | Tech Stack |
| :--- | :--- |
| **Frontend** | **Swift / SwiftUI** (iOS App), **Xcode** |
| **AI Models** | **GPT-4o (Vision)**, **GPT Realtime API** |
| **Backend** | **Node.js**, **PrismaDB**, **WebSockets** |
| **Infrastructure** | **AWS S3**, HTTP API |
| **Hardware** | **Meta Ray-Ban Smart Glasses** |

---

## üßë‚Äçüíª Team Members

| **Name** | **Role** | 
|:-----------:|:---------------:|
| **User Name** | VR Software Engineer / Backend (Node.js) |
| **Donghun Yoo** | Collaborator |
| (Other Members) | ... |

---

## üìÇ Project Deliverables

- [Presentation Pitch Deck (PDF)](./White%20Blue%20and%20Grey%20Modern%20Startup%20Pitch%20Deck%20Presentation.pdf)
- [Demo Video Link](https://www.youtube.com/watch?v=YOUR_VIDEO_ID)

---
<div align="center">
  <p><i>Developed during MIT Reality Hack 2026</i></p>
</div>
